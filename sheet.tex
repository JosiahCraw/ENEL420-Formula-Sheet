\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[section]{placeins}
\graphicspath{ {./img/} }
\usepackage[a4paper]{geometry}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{tabto}
\usepackage{physics}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\usepackage{chemformula}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage{float}
\usepackage{tabto}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage[section]{placeins}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{array}
\usepackage{gensymb}
\usepackage{array}
\usetikzlibrary{shapes, arrows}

% Document Parameters
\newcommand\reportTitle{ENEL420 Formula Sheet}
\newcommand\subTitle{The bitchiest of all the exams}

\newcommand\todo[1]{\textcolor{red}{#1}}


\author{{\LARGE Josiah Craw}\vspace{10pt}\\jcr124@uclive.ac.nz\\}
\title{\rule{\textwidth}{0.8pt} \\ {\huge \textbf{\reportTitle}}\\{\large \subTitle} \rule{\textwidth}{0.8pt}}

\begin{document}
% Titlepage
\maketitle
\newpage

\section{Interpolation}
Interpolation, convolution with a kernel function:
\begin{equation}
f(k_0) = \sum_k f(k) \frac{K(k_0-k)}{\textrm{convolution kernel}} 
\end{equation}
Where $f(k_0)$ is the interpolated signal and $f(k)$ is the data

\subsection{Kernels}

Nearest Neighbour:
\begin{equation}
K(x)=\textrm{rect}(x) =
\begin{cases}
    1 \quad |x| \leq \frac{1}{2}\\
    0 \quad \textrm{otherwise}
\end{cases}
\end{equation}

Linear:
\begin{equation}
    K(x)=\textrm{tri}(x) =
    \begin{cases}
        1 - |x| \quad |x| < 1\\
        0 \quad \textrm{otherwise}
    \end{cases}
\end{equation}

Sinc:
\begin{equation}
    K(x) = \textrm{sinc}(x) = \frac{\textrm{sin}(\pi x)}{\pi x}
\end{equation}

\section{Aliasing}
General Case to avoid aliasing:
\begin{equation}
    \frac{2f_u}{n} < f_s < \frac{2f_l}{n-1}
\end{equation}

Where,
\begin{equation}
    1 \leq n \leq I_{MLT}\left(\frac{f_u}{B}\right)
\end{equation}

$I_{MLT}$ is Maximum integer less than

\section{Z-Transform}
\begin{equation}
    F(z)=\sum_{n=0}^{\infty}f(n)z^{-n}
\end{equation}

Or,
\begin{equation}
    F(s)=\sum_{n=0}^{\infty}f(nT)e^{-nTs}
\end{equation}

\section{Quantisation Noise}

RMS quantisation noise:
\begin{equation}
    \sigma = \frac{\Delta}{\sqrt{12}} = \frac{\Delta}{2\sqrt{3}}
\end{equation}

Noise Power:
\begin{equation}
    \textrm{NP} \propto \Delta^2
\end{equation}

Therefore is noise power is decreased by $\frac{1}{2}$,
\begin{equation}
    10\textrm{log}_{10}\left(\frac{1}{2}^2\right) = 6\textrm{dB}
\end{equation}

\section{Filters}

Direct realisation:
\begin{equation}
    H(z) = \frac{\sum_{k=0}^K b_k z^{-k}}{1+\sum_{m=1}^M a_m z^{-m}}
\end{equation}

Linear Phase, if a filter has linear phase it can be expressed in the form:
\begin{equation}
    H(\omega) = |H(\omega)|e^{j\theta(\omega)}
\end{equation}

Where,
\begin{equation}
    \theta(\omega) = -(\alpha\omega+\beta)
\end{equation}

Windowing the impulse response is defined by the inverse Fourier Transform,
\begin{equation}
    h_D(n) = \frac{1}{2\pi} \int_{-\pi}^\pi H_D(\omega)e^{j\omega n} \quad d\omega 
\end{equation} 

non-recursive FIR Filters,
\begin{equation}
    y(n) = b_0 x(n) + b_1 x(n-1)
\end{equation}

Recursive,
\begin{equation}
    y(n) = a y(n-1) + bx(n)
\end{equation}

So,
\begin{equation}
    H(z) = \sum_{n=0}^{N-1} \frac{1}{N} \sum_{k=0}^{N-1} H(k) e^{\frac{j2\pi kn}{N}}z^{-n} 
\end{equation}

\section{Detection Theory}

Likelihood Ratio,
\begin{equation}
    \frac{p(\textbf{x}|H_0)}{p(\textbf{x}|H_1)}
\end{equation}

\subsection{Likelihood ratio test}

Choose null hypothesis if,
\begin{equation}
    \frac{p(\textbf{x}|H_0)}{p(\textbf{x}|H_1)} > \gamma
\end{equation}

Choose alternitive hypothesis if,
\begin{equation}
    \frac{p(\textbf{x}|H_0)}{p(\textbf{x}|H_1)} \leq \gamma
\end{equation}

\subsection{Log Likelihood}
Choose null hypothesis if,
\begin{equation}
    -x[0] + \frac{1}{2} > 0 \leftrightarrow x[0] < \frac{1}{2}
\end{equation}

Choose alternitive hypothesis if,
\begin{equation}
    -x[0] + \frac{1}{2} \leq 0 \leftrightarrow x[0] \geq \frac{1}{2}
\end{equation}

Solve for $\gamma$ using,
\begin{equation}
    P_{FA} = \int_{\textbf{x}:L(\textbf{x})<\gamma}p(\textbf{x}|H_0)d\textbf{x}
\end{equation}

\subsection{Missed Detection}

The probability of missed detection is,
\begin{equation}
    P_M = p(x[0] \leq \frac{1}{2}| H_1) = p(x[0] \leq \frac{1}{2}|u = 1)
\end{equation}

\subsection{Detection Error Rate}

\begin{equation}
    P_{FA}P(H_0) + P_MP(H_1)
\end{equation}

Where $P_{FA}$ is the probability of falsely selecting the alternative hypothesis and $P_M$ is the probability
of falsely selecting the null hypothesis.

\subsection{Detection Threshold}
To find the detection threshold use the following,
\begin{equation}
    P_{FA} = \int_{\textbf{x}} 1(\textrm{log}(L(\textbf{x})) - c < \gamma) \cdot p(\textrm{log}(L(\textbf{x})) - c|H_0) \quad d\textbf{x} 
\end{equation}

\subsection{NP Detector of Known Signal in WGN}
The signal likelihood under $w[n]~N(0,\sigma^2)$ (Normal distribution) for the null hypothesis,
\begin{equation}
    p(\textbf{x}|H_0) = \prod_{n=0}^{N-1} \frac{1}{\sqrt{2\pi}\sigma}\textrm{exp}\left(-\frac{x[n]^2}{2\sigma^2}\right)
\end{equation}

For the alternative hypothesis,
\begin{equation}
    p(x|H_1) = \prod_{n=0}^{N-1}  \frac{1}{\sqrt{2\pi}\sigma}\textrm{exp}\left(-\frac{(x[n]-s[n])^2}{2\sigma^2}\right)
\end{equation}

Therefore the Log-Likelihood ratio test is,
\begin{equation}
    \textrm{log}(L(\textbf{x})) = log\left(\frac{p(\textbf{x}|H_0)}{p(\textbf{x}|H_1)}\right) = \frac{1}{2\sigma^2} \sum_{n=0}^{N-1} (s[n]^2 - 2s[n]x[n])
\end{equation}

\subsection{Multivariate Gaussian PDF}

Null Hypothesis,
\begin{equation}
    P(\textbf{x}|H_0) = \frac{\textbf{1}}{(\sqrt{2\pi}\sigma)^N} \textrm{exp} \left(- \frac{1}{2\sigma^2} \textbf{x}^T \textbf{x} \right) (\delta = \sigma^2\textbf{I})
\end{equation}

Alternative Hypothesis,
\begin{equation}
    P(\textbf{x}|H_1) = \frac{\textbf{1}}{ | 2\pi(\textbf{C}+\sigma^2\textbf{I})| } exp \left(-\frac{1}{2}\textbf{x}^T(\textbf{C}+\sigma^2\textbf{I})^{-1}\textbf{x}\right)(\Delta = \textbf{C} + \sigma^2\textbf{I})
\end{equation}

LLR,
\begin{equation}
    \textrm{log}(L(\textbf{x})) \propto -\textbf{x}^T\textbf{C}(\textbf{C}+\sigma^2\textbf{I})^{-1}\textbf{x}
\end{equation}

Simplified,
\begin{equation}
    \sum_{n=0}^{N=1} \frac{\delta_n}{\delta_n+\sigma^2}y[n]^2
\end{equation}

\subsection{Mixture Model}
\begin{equation}
    p(\textbf{x} | \theta) = \sum_{k=1}^K w_k p_k (\textbf{x} | \theta)
\end{equation}

Where, $p_k(\textbf{x}|\theta)$ is the $k^{\textrm{th}}$ base distribution and is the mixing weight of $p_k(\textbf{x}|\theta)$ Where,
\begin{equation}
    w_k \geq 0 \quad \textrm{and} \quad \sum_{k=1}^K w_k = 1
\end{equation}

\section{Fourier Transform}

\subsection{Properties}

Shift Theorem
\begin{equation}
    x(t-t_0) \leftrightarrow X(f)\textrm{exp}(-j2\pi ft_0)
\end{equation}

Scaling
\begin{equation}
    x(at) \leftrightarrow \frac{1}{ |a| } X \left(\frac{f}{a}\right)
\end{equation}

Convolution
\begin{equation}
    x(t) \otimes y(t) \leftrightarrow X(f)Y(f)
\end{equation}

For a real signal
\begin{equation}
    X(-f) = X^*(f)
\end{equation}

DFT
\begin{equation}
    X(k) = \frac{1}{N} \sum_{n=0}^{N-1} x(n) \textrm{exp}(-j2\pi nk / N)
\end{equation}

IDFT
\begin{equation}
    x(n) = \sum_{k=0}^{N-1} X(k) \textrm{exp} (j2\pi nk/N)
\end{equation}

Parseval's Theorem
\begin{equation}
    \sum_{n=0}^{N-1} [f(n)]^2 = \sum_{k=0}^{N-1}|F(k)|^2
\end{equation}

2D Fourier Transform can be expressed as a weighted sum of harmonics,
\begin{equation}
    \textrm{exp}(j2\pi (ux+vy))
\end{equation}

\subsection{2D FT}

\begin{equation}
    F(u,v) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \textrm{exp} (-j2\pi (ux+vy))dx dy
\end{equation}

2D DFT,
\begin{equation}
    F(p,q) = \frac{1}{N} \sum_{m=0}^{N-1} \left(\frac{1}{N} \sum_{n=0}^{N-1} f(m,n) \textrm{exp} (-j2\pi qn/N)\textrm{}\right) \textrm{exp} (-j2\pi pm / N)
\end{equation}

Rotation of an image rotating by $\alpha$,
\begin{equation}
    F_\alpha (\rho;\phi) = \int_0^{2\pi} \int_0^{\infty} f(r;\theta) \textrm{exp} (-j2\pi\rho r \textrm{cos}(\theta-\phi))r drd\theta
\end{equation}

So,
\begin{equation}
    F_\alpha (\rho;\phi) = F(\rho;\phi-\alpha)
\end{equation}

\section{Projection}

\begin{equation}
    P(\theta,x') = \int_{-\infty}^\infty f(x',y')dy'
\end{equation}

\subsection{Wiener filtering}
\begin{equation}
    W(u,v) = \frac{H^*(u,v)}{ |H(u,v)|^2 + \Phi(u,v) }
\end{equation}

Where $\Phi(u,v)$ is an estimate of the spatial frequency dependent noise-to-signal power

The estimate of the image spectrum is given by,
\begin{equation}
    \hat{F}(u,v) = G(u,v)W(u,v)
\end{equation}

If $H(u,v)$ is large,
\begin{equation}
    \hat{F}(u,v) \approx F(u,v) + \frac{N(u,v)}{H(u,v)} \approx F(u,v)
\end{equation}

However when $H(u,v)$ is small,
\begin{equation}
    \hat{F}(u,v) = G(u,v)\left(\frac{H^*(u,v)}{ |H(u,v)|^2 + \Phi}\right) \approx G(u,v) \frac{H^*(u,v)}{\Phi} \approx 0
\end{equation}

\section{Diffraction}

The phase difference is,
\begin{equation}
    \phi = (d_1-d_2)\left(\frac{2\pi}{\lambda}\right) = (\vb{x} \cdot \vb{\hat{k_0}} - \vb{x} \cdot \vb{\hat{k}}) \left(\frac{2\pi}{\lambda}\right)
\end{equation}

So,
\begin{equation}
    \phi = -\vb{x} \cdot (\vb{k}-\vb{k_0})
\end{equation}

Therefore the total scattering is,
\begin{equation}
    \psi(\vb{k}) = \int f(\vb{x}) \textrm{exp}(i(\vb{k}-\vb{k_0}) \cdot \vb{x}) d\vb{x}
\end{equation}

The scattering vector is defined as,
\begin{equation}
    \vb{u} = (\vb{\hat{k}}-\vb{\hat{k_0}})/\lambda
\end{equation}

Therefore the scattered field in terms of $\vb{u}$ is,
\begin{equation}
    F(\vb{u})=\int f(\vb{x}) \textrm{exp}(i2\pi \vb{u} \cdot \vb{x}) d\vb{x}
\end{equation}

Therefore by taking the inverse Fourier transform the object can be reconstructed,
\begin{equation}
    f(\vb{x}) = \int F(\vb{u}) \textrm{exp} (-i2\pi \vb{u} \cdot \vb{x}) d\vb{u}
\end{equation}

\newpage

\section{Notes}
\todo{NOTE: These are mostly guesses, I'm not very good at this subject} 

\subsection{Bandpass sampling}
Bandpass sampling is the uses the low bandwidth of a signal to allow for reduction
in the sampling frequency, this is possible due to the Nyquist sampling rate
designed for use in low pass systems. This results in a convolution with no overlap
resulting in no aliasing while sampling at less than the Nyquist rate.


\subsection{Le's Free Marks}
Using the trace of the matrix,
\begin{equation}
    E(tr(a^T\psi_1\psi_2^Ta))
\end{equation}

And because,
\begin{equation}
    tr(AB) = tr(BA)
\end{equation}

Therefore,
\begin{equation}
    tr(\psi_1\psi_2^T)
\end{equation}

Which,
\begin{equation}
    tr(\psi_2^T\psi_1) = 0
\end{equation}

\end{document}
